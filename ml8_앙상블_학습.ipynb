{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml8 앙상블 학습.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJREOSa0DWW8AGOB0j4Ay+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kani215/ML_study/blob/main/ml8_%EC%95%99%EC%83%81%EB%B8%94_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 투표 기반 분류기 \n",
        "- 로지스틱 회귀 분류기\n",
        "- svm 분류기\n",
        "- 랜덤 포레스트 분류기\n",
        "- kmeans 분류기\n",
        "중 가장 잘 맞춘 녀석을 선택하는 앙상블 수법"
      ],
      "metadata": {
        "id": "fpErK4Ya9ybt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "log_clf=LogisticRegression()\n",
        "rnd_clf=RandomForestClassifier()\n",
        "svm_clf=SVC()\n",
        "\n",
        "X,y=make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\n",
        "\n",
        "voting_clf=VotingClassifier(\n",
        "    estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
        "    voting='hard')\n",
        "voting_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "_ncH4kih9ygM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722f04ef-1ef2-45f6-9e2f-25a02288dee1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "VdNNc6aaHfX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b06300-e052-4d77-acdf-0d60da25d9c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.2 배깅과 페이스팅 기법\n",
        "- 예제는 500개의 분류기를 앙상블 훈련 시키는 코드\n",
        "- 각 분류기는 무작위로 100개 샘플로 추려 그거를 훈련한 것 "
      ],
      "metadata": {
        "id": "XfS1x9AC_Ajf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators = 500,\n",
        "    max_samples=100, bootstrap=True, n_jobs=-1    \n",
        ")\n",
        "bag_clf.fit(X_train,y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "U8uevq86_Apn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.3 oob 평가법\n",
        "- 배깅을 사용하면 아예 선택이 안되는 샘플이 37%정도 발생\n",
        "- 이를 이용하여 검증 세트로 사용하는 것\n",
        "- 앙상블의 평가는 각 예측기의 oob 평가를 평균하여 얻는다.\n",
        "\n"
      ],
      "metadata": {
        "id": "1LEEClbuAD9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators = 500,\n",
        "    bootstrap=True, n_jobs=-1, oob_score = True    \n",
        ")\n",
        "bag_clf.fit(X_train, y_train)\n",
        "bag_clf.oob_score_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g49_qkEPACoT",
        "outputId": "166155ad-f118-464d-aebc-85b1b50d687f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9013333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SjhrP-auONDH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.1 랜덤 포레스트\n",
        "- 훈련 샘플로 부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련시킴\n",
        "- 예측을 하려면 모든 개별 트리의 예측을 구하면 됩니다.\n"
      ],
      "metadata": {
        "id": "fE64Li0-9x_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500,max_leaf_nodes=16,n_jobs=-1)\n",
        "rnd_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "X9-fT5RV9yKt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "500개 트리로 구성된 랜덤 포레스트로 분류 학습\n",
        "\n",
        "트리의 노드를 분할 할 때, 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성 주입"
      ],
      "metadata": {
        "id": "_otCN4LUBrHd"
      }
    }
  ]
}